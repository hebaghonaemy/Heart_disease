{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree final project \n",
    "\n",
    "\n",
    "## Project: Heart Disease Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualization code visuals.py\n",
    "# import visuals as vs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "* age : age in years \n",
    "\n",
    "\n",
    "* sex : (1 = male; 0 = female) \n",
    "\n",
    "\n",
    "* cp : chest pain type \n",
    "\n",
    "\n",
    "* trestbps : resting blood pressure (in mm Hg on admission to the hospital) \n",
    "\n",
    "\n",
    "* chol : serum cholestoral in mg/dl \n",
    "\n",
    "\n",
    "* fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "\n",
    "\n",
    "* restecg : resting electrocardiographic results \n",
    "\n",
    "\n",
    "* thalach : maximum heart rate achieved \n",
    "\n",
    "\n",
    "* exang : exercise induced angina (1 = yes; 0 = no) \n",
    "\n",
    "\n",
    "* oldpeak : ST depression induced by exercise relative to rest \n",
    "\n",
    "\n",
    "* slope : the slope of the peak exercise ST segment \n",
    "\n",
    "\n",
    "* ca : number of major vessels (0-3) colored by flourosopy \n",
    "\n",
    "\n",
    "* thal : 3 = normal; 6 = fixed defect; 7 = reversable defect \n",
    "\n",
    "\n",
    "* target : have disease or not (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 total features after one-hot encoding.\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target label\n",
    "target = data['target']\n",
    "features = data.drop('target', axis = 1)\n",
    "\n",
    "encoded = list(data.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "print (encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  ca  \\\n",
       "0   63    1       145   233    1        0      150      0      2.3   0   \n",
       "1   37    1       130   250    0        1      187      0      3.5   0   \n",
       "2   41    0       130   204    0        0      172      0      1.4   0   \n",
       "3   56    1       120   236    0        1      178      0      0.8   0   \n",
       "4   57    0       120   354    0        1      163      1      0.6   0   \n",
       "\n",
       "    ...     cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  thal_3  slope_0  \\\n",
       "0   ...        0     0     1       0       1       0       0        1   \n",
       "1   ...        0     1     0       0       0       1       0        1   \n",
       "2   ...        1     0     0       0       0       1       0        0   \n",
       "3   ...        1     0     0       0       0       1       0        0   \n",
       "4   ...        0     0     0       0       0       1       0        0   \n",
       "\n",
       "   slope_1  slope_2  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        1  \n",
       "3        0        1  \n",
       "4        0        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.get_dummies(features['cp'], prefix = \"cp\")\n",
    "\n",
    "b = pd.get_dummies(features['thal'], prefix = \"thal\")\n",
    "\n",
    "c = pd.get_dummies(features['slope'], prefix = \"slope\")\n",
    "\n",
    "frames = [features, a, b, c]\n",
    "\n",
    "features = pd.concat(frames, axis = 1)\n",
    "\n",
    "features = features.drop(['cp', 'thal', 'slope'] , axis = 1)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 242 samples.\n",
      "Testing set has 61 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "Diagnostic tests are often used with sensitivity as the headline metrics.\n",
    "\n",
    ">Sensitivity is the proportion of truly diseased persons in the screened population who are identified as diseased by the screening test (i.e. they have high scores). Sensitivity indicates the probability that the test will correctly diagnose a case, or the probability that any given case will be identified by the test.\n",
    "\n",
    "so we will be using the same metrice (sensitivity) aka Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score,precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(X, y , learner , params):\n",
    "      \n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "   \n",
    "    scoring_fnc = make_scorer(accuracy_score)\n",
    "\n",
    "    grid = GridSearchCV(learner, params, scoring = scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using K-NN we get an accuracy score of:  70.492 %\n",
      "Recall Score:  0.705882352941\n",
      "Using k-NN we get a recall score of:  70.588 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_params = {'n_neighbors':[i for i in range(1,30,2)]}\n",
    "\n",
    "knn_model = train_predict(X_train , y_train , knn , knn_params)\n",
    "\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "print('Using K-NN we get an accuracy score of: ',\n",
    "     round(accuracy_score(y_test,knn_pred),5)*100,'%')\n",
    "\n",
    "print('Recall Score: ',recall_score(y_test , knn_pred))\n",
    "\n",
    "print('Using k-NN we get a recall score of: ',\n",
    "      round(recall_score(y_test,knn_pred),5)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.639344262295\n",
      "Using SVM we get an accuracy score of:  63.934 %\n",
      "Recall Score:  0.970588235294\n",
      "Using SVM we get a recall score of:  97.059 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "                        \n",
    "\n",
    "svm_params = {'gamma' : [0.001, 0.01, 0.1, 1],'C':[0.001, 0.01, 0.1]}\n",
    "\n",
    "svm_model = train_predict(X_train , y_train , svm , svm_params)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test , svm_pred))\n",
    "\n",
    "print('Using SVM we get an accuracy score of: ',\n",
    "      round(accuracy_score(y_test,svm_pred),5)*100,'%')\n",
    "\n",
    "print('Recall Score: ',recall_score(y_test , svm_pred))\n",
    "\n",
    "print('Using SVM we get a recall score of: ',\n",
    "      round(recall_score(y_test,svm_pred),5)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.868852459016\n",
      "Using GaussianNB we get an accuracy score of:  86.885 %\n",
      "Recall Score:  0.882352941176\n",
      "Using GaussianNB we get a recall score of:  88.235 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test , y_pred))\n",
    "\n",
    "print('Using GaussianNB we get an accuracy score of: ',\n",
    "      round(accuracy_score(y_test,y_pred),5)*100,'%')\n",
    "\n",
    "print('Recall Score: ',recall_score(y_test , y_pred))\n",
    "\n",
    "print('Using GaussianNB we get a recall score of: ',\n",
    "      round(recall_score(y_test,y_pred),5)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.83606557377\n",
      "Using Decision Tree we get an accuracy score of:  83.607 %\n",
      "Recall Score:  0.882352941176\n",
      "Using Decision Tree we get a recall score of:  88.235 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt_params = {'max_depth':[2,4,6,8],'min_samples_leaf':[2,4,6,8], 'min_samples_split':[2,4,6,8]}\n",
    "\n",
    "dt_model = train_predict(X_train , y_train , dt , dt_params)\n",
    "\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test , dt_pred))\n",
    "\n",
    "print('Using Decision Tree we get an accuracy score of: ',\n",
    "      round(accuracy_score(y_test,dt_pred),5)*100,'%')\n",
    "\n",
    "print('Recall Score: ',recall_score(y_test , dt_pred))\n",
    "\n",
    "print('Using Decision Tree we get a recall score of: ',\n",
    "      round(recall_score(y_test,y_pred),5)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6YAAAE3CAYAAAC5J1wkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd928d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"KNN\", \"SVM\", \"GaussianNB\", \"Decision Tree\"]\n",
    "recall = [70.588, 97.059, 88.235, 88.235 ]\n",
    "colors = [\"blue\", \"green\", \"orange\", \"yellow\"]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.yticks(np.arange(0,100,10))\n",
    "plt.ylabel(\"Recall %\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "sns.barplot(x = models, y = recall, palette = colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM has the highest recall score. But it also has low accuracy (compared to the other models).\n",
    "#### GaussianNB and Decision Tree both come in second. with almost the same results for both Recall and Accuracy.\n",
    "#### KNN has the worst results when it comes to Recall. still it scores around 70% which is higher than some of the used tests for detecting heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
